{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNT6qMYc/LSTvqAIQ3ZaR1V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeepthiTabithaBennet/NaturalLanguageProcessing/blob/main/TextRep_Doc2Vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejxasyzHiDMP",
        "outputId": "50961a34-f9fd-4648-a1b3-395f9bb49943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.4)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MJ6mSHqhZNH",
        "outputId": "f7a19c4f-ee7b-4ca3-f9e0-7dc5c8fc58e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector for the new sentence: [ 4.72261105e-03  6.72688102e-03  9.27181169e-03  5.47953695e-03\n",
            "  5.16829081e-03  5.49017265e-03 -2.18511466e-03  1.05680479e-02\n",
            " -3.92303150e-03  3.92060960e-03  1.00852028e-02  4.72586798e-05\n",
            " -1.16804289e-03  3.24215461e-03 -7.09559955e-03  3.66169470e-03\n",
            " -4.36637551e-04 -8.31920840e-03 -4.52698953e-03  3.96481575e-03\n",
            " -4.42491379e-03  1.04362154e-02 -1.17365026e-03 -3.19059705e-03\n",
            " -8.82375147e-03  9.66457243e-04 -5.86954970e-03 -1.13134263e-02\n",
            " -8.34899489e-03  1.42220454e-03  1.05380500e-02  5.43269969e-04\n",
            " -9.09433607e-03 -7.33674271e-03 -2.86207534e-03  3.38522368e-03\n",
            "  1.10703462e-03 -9.76164732e-03  1.04220435e-02 -7.25680916e-03\n",
            " -2.38288753e-03  1.31552545e-02  2.09682016e-03 -9.28900950e-03\n",
            "  1.94098288e-03  4.48812405e-03  6.01902790e-03  1.34276669e-03\n",
            "  1.16752665e-02 -8.37264161e-05]\n",
            "Most similar documents:\n",
            "Document ID: 1 Similarity: 0.4606287479400635 Document: Natural language processing is a fascinating field.\n",
            "Document ID: 3 Similarity: 0.36943721771240234 Document: Doc2Vec is an extension of Word2Vec.\n",
            "Document ID: 0 Similarity: 0.17240428924560547 Document: I love programming in Python.\n",
            "Document ID: 2 Similarity: 0.13167965412139893 Document: Machine learning and deep learning are subsets of artificial intelligence.\n",
            "Document ID: 4 Similarity: 0.03965259715914726 Document: Gensim provides efficient implementations of popular NLP algorithms.\n"
          ]
        }
      ],
      "source": [
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from gensim.utils import simple_preprocess\n",
        "\n",
        "# Sample data\n",
        "documents = [\n",
        "    \"I love programming in Python.\",\n",
        "    \"Natural language processing is a fascinating field.\",\n",
        "    \"Machine learning and deep learning are subsets of artificial intelligence.\",\n",
        "    \"Doc2Vec is an extension of Word2Vec.\",\n",
        "    \"Gensim provides efficient implementations of popular NLP algorithms.\"\n",
        "]\n",
        "\n",
        "# Preprocess data: tokenization\n",
        "tagged_data = [TaggedDocument(words=simple_preprocess(doc), tags=[str(i)]) for i, doc in enumerate(documents)]\n",
        "\n",
        "# Initialize and train Doc2Vec model\n",
        "model = Doc2Vec(vector_size=50, window=2, min_count=1, epochs=100)\n",
        "model.build_vocab(tagged_data)\n",
        "model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)\n",
        "\n",
        "# Infer vector for a new sentence\n",
        "new_sentence = \"I am learning about Doc2Vec.\"\n",
        "new_sentence_vector = model.infer_vector(simple_preprocess(new_sentence))\n",
        "\n",
        "print(\"Vector for the new sentence:\", new_sentence_vector)\n",
        "\n",
        "# Find most similar documents to the new sentence\n",
        "similar_docs = model.dv.most_similar([new_sentence_vector])\n",
        "print(\"Most similar documents:\")\n",
        "for doc_id, similarity in similar_docs:\n",
        "    print(\"Document ID:\", doc_id, \"Similarity:\", similarity, \"Document:\", documents[int(doc_id)])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s803k70co84z",
        "outputId": "345dddb6-bd73-4973-c170-6c39da5c2145"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# define a list of documents.\n",
        "data = [\n",
        "    \"I love programming in Python.\",\n",
        "    \"Natural language processing is a fascinating field.\",\n",
        "    \"Machine learning and deep learning are subsets of artificial intelligence.\",\n",
        "    \"Doc2Vec is an extension of Word2Vec.\",\n",
        "    \"Gensim provides efficient implementations of popular NLP algorithms.\"\n",
        "]\n",
        "\n",
        "# preproces the documents, and create TaggedDocuments\n",
        "tagged_data = [TaggedDocument(words=word_tokenize(doc.lower()),\n",
        "\t\t\t\t\t\t\ttags=[str(i)]) for i,\n",
        "\t\t\tdoc in enumerate(data)]\n",
        "\n",
        "# train the Doc2vec model\n",
        "model = Doc2Vec(vector_size=20,\n",
        "\t\t\t\tmin_count=2, epochs=50)\n",
        "\n",
        "model.build_vocab(tagged_data)\n",
        "\n",
        "model.train(tagged_data,\n",
        "\t\t\ttotal_examples=model.corpus_count,\n",
        "\t\t\tepochs=model.epochs)\n",
        "\n",
        "# get the document vectors\n",
        "document_vectors = [model.infer_vector(\n",
        "\tword_tokenize(doc.lower())) for doc in data]\n",
        "\n",
        "# print the document vectors\n",
        "for i, doc in enumerate(data):\n",
        "\tprint(\"Document\", i+1, \":\", doc)\n",
        "\tprint(\"Vector:\", document_vectors[i])\n",
        "\tprint()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BReWimbcnX1M",
        "outputId": "0aaf0e54-7f2f-45a9-9a2d-5b480783decd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document 1 : I love programming in Python.\n",
            "Vector: [ 0.00468896 -0.00651363 -0.00624672 -0.01846151 -0.00022137 -0.02485958\n",
            "  0.01064255  0.02412496 -0.02449686 -0.00298595  0.01080469  0.02459338\n",
            " -0.01282512 -0.00505272  0.00191159 -0.01186773  0.01923111 -0.00104116\n",
            "  0.02097891 -0.01662402]\n",
            "\n",
            "Document 2 : Natural language processing is a fascinating field.\n",
            "Vector: [-0.01388139  0.01655041 -0.00023787  0.00953289 -0.02298607  0.01190146\n",
            " -0.01248948 -0.01475126  0.00889673  0.02166019 -0.01868207 -0.00650447\n",
            " -0.0083094  -0.00708576  0.00116256  0.00897374  0.02481955 -0.00533592\n",
            " -0.01768001  0.01152035]\n",
            "\n",
            "Document 3 : Machine learning and deep learning are subsets of artificial intelligence.\n",
            "Vector: [-0.00878998  0.0170193   0.0158102  -0.00970508  0.02302436  0.01707866\n",
            "  0.00563933 -0.02454659 -0.01118153 -0.02517018  0.01681244 -0.01689572\n",
            "  0.01943532  0.00386697 -0.02514085 -0.01512298 -0.00418437 -0.00468899\n",
            "  0.00149293 -0.01320517]\n",
            "\n",
            "Document 4 : Doc2Vec is an extension of Word2Vec.\n",
            "Vector: [-0.01862356 -0.01504134 -0.0120038   0.01998885  0.00790407  0.01564564\n",
            "  0.00953528  0.00221436  0.0012923   0.01915151  0.01235852 -0.00459228\n",
            " -0.0050088   0.01157742  0.01472438  0.00583077 -0.0170114   0.00180373\n",
            "  0.0230807  -0.01508141]\n",
            "\n",
            "Document 5 : Gensim provides efficient implementations of popular NLP algorithms.\n",
            "Vector: [-1.42506901e-02  1.97051049e-05 -1.78590976e-02  1.27845425e-02\n",
            " -1.59224868e-02 -2.05201637e-02  9.20756441e-03  2.27971710e-02\n",
            " -5.89672849e-03 -2.21916777e-03  1.66579476e-03  9.01834294e-03\n",
            " -1.67123955e-02  7.68784853e-03 -7.13604037e-03  2.90273037e-03\n",
            "  1.49332657e-02  2.28862409e-02  6.45517325e-03  5.91790630e-03]\n",
            "\n"
          ]
        }
      ]
    }
  ]
}